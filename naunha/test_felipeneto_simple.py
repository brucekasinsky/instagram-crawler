#!/usr/bin/env python3
"""
Script simples para teste rÃ¡pido do Felipe Neto
"""

from InstaScraperV2 import ScraperController
import json

def quick_test():
    """Teste rÃ¡pido e direto"""
    print("ğŸš€ Teste RÃ¡pido - Felipe Neto")
    print("-" * 40)
    
    # Criar scraper
    scraper = ScraperController()
    
    try:
        # Testar proxy
        print("1. Testando proxy...")
        if scraper.test_proxy_connection():
            print("âœ… Proxy OK")
        else:
            print("âŒ Proxy falhou")
            return
        
        # Criar sessÃ£o
        print("2. Criando sessÃ£o...")
        scraper.create_session()
        print("âœ… SessÃ£o criada")
        
        # Obter dados do perfil
        print("3. Obtendo dados do perfil...")
        profile = scraper.get_profile_data("felipeneto")
        
        if profile:
            print("âœ… Perfil obtido!")
            print(f"   Nome: {profile['full_name']}")
            print(f"   Seguidores: {profile['followers']:,}")
            print(f"   Posts: {profile['uploads']:,}")
            print(f"   Bio: {profile['description'][:50]}...")
            
            # Salvar em JSON
            with open('felipeneto_profile.json', 'w', encoding='utf-8') as f:
                json.dump(profile, f, ensure_ascii=False, indent=2)
            print("ğŸ’¾ Dados salvos em felipeneto_profile.json")
        else:
            print("âŒ Falha ao obter perfil")
        
        # Obter posts
        print("4. Obtendo posts...")
        
        # Primeiro, navegar para a pÃ¡gina e capturar screenshot
        print("   Navegando para a pÃ¡gina do perfil...")
        scraper.browser.get('https://instagram.com/felipeneto/')
        
        # Aguardar um pouco para a pÃ¡gina carregar
        import time
        time.sleep(5)
        
        # Capturar screenshot
        print("   Capturando screenshot da pÃ¡gina...")
        screenshot_path = "felipeneto_page_screenshot.png"
        scraper.browser.save_screenshot(screenshot_path)
        print(f"   ğŸ“¸ Screenshot salvo em: {screenshot_path}")
        
        # Obter HTML da pÃ¡gina para anÃ¡lise
        print("   Salvando HTML da pÃ¡gina...")
        html_content = scraper.browser.page_source
        with open("felipeneto_page.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        print("   ğŸ“„ HTML salvo em: felipeneto_page.html")
        
        # Agora tentar obter os posts
        posts = scraper.get_creator_posts("felipeneto")
        
        if posts:
            print(f"âœ… {len(posts)} posts obtidos!")
            
            # Mostrar resumo
            total_likes = sum(p.get('likes', 0) for p in posts)
            print(f"   Total de likes: {total_likes:,}")
            
            # Salvar em JSON
            with open('felipeneto_posts.json', 'w', encoding='utf-8') as f:
                json.dump(posts, f, ensure_ascii=False, indent=2)
            print("ğŸ’¾ Posts salvos em felipeneto_posts.json")
        else:
            print("âŒ Falha ao obter posts")
        
        print("\nğŸ‰ Teste concluÃ­do!")
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
    
    finally:
        scraper.quit_session()

if __name__ == "__main__":
    quick_test()
